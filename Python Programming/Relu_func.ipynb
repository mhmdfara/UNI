{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0cec10-3134-4b64-9023-76e1ae4aebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1875/1875 [==============================] - 30s 15ms/step - loss: 1.2274 - accuracy: 0.5423 - val_loss: 0.7543 - val_accuracy: 0.7092 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.9280 - accuracy: 0.6529 - val_loss: 0.6557 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.8468 - accuracy: 0.6823 - val_loss: 0.6260 - val_accuracy: 0.7625 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.7999 - accuracy: 0.7025 - val_loss: 0.6238 - val_accuracy: 0.7672 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.7652 - accuracy: 0.7164 - val_loss: 0.5504 - val_accuracy: 0.8031 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.7495 - accuracy: 0.7236 - val_loss: 0.5662 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.7258 - accuracy: 0.7343 - val_loss: 0.5731 - val_accuracy: 0.7883 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.7099 - accuracy: 0.7408 - val_loss: 0.5501 - val_accuracy: 0.7912 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.6977 - accuracy: 0.7456 - val_loss: 0.5381 - val_accuracy: 0.7978 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6896 - accuracy: 0.7493 - val_loss: 0.5136 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.6748 - accuracy: 0.7532 - val_loss: 0.4948 - val_accuracy: 0.8172 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.6686 - accuracy: 0.7556 - val_loss: 0.5202 - val_accuracy: 0.8084 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.6603 - accuracy: 0.7577 - val_loss: 0.4861 - val_accuracy: 0.8293 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.6537 - accuracy: 0.7613 - val_loss: 0.4937 - val_accuracy: 0.8208 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6512 - accuracy: 0.7626 - val_loss: 0.5340 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.6414 - accuracy: 0.7670 - val_loss: 0.4963 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6386 - accuracy: 0.7680 - val_loss: 0.4925 - val_accuracy: 0.8264 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6291 - accuracy: 0.7721 - val_loss: 0.5374 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6340 - accuracy: 0.7713 - val_loss: 0.4977 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.6260 - accuracy: 0.7735 - val_loss: 0.4861 - val_accuracy: 0.8323 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.6193 - accuracy: 0.7763 - val_loss: 0.5002 - val_accuracy: 0.8260 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.6205 - accuracy: 0.7749 - val_loss: 0.4885 - val_accuracy: 0.8235 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6196 - accuracy: 0.7765 - val_loss: 0.4978 - val_accuracy: 0.8156 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6100 - accuracy: 0.7801 - val_loss: 0.4877 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6066 - accuracy: 0.7818 - val_loss: 0.4782 - val_accuracy: 0.8212 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6081 - accuracy: 0.7797 - val_loss: 0.5798 - val_accuracy: 0.7683 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.6043 - accuracy: 0.7816 - val_loss: 0.5088 - val_accuracy: 0.8249 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.6007 - accuracy: 0.7817 - val_loss: 0.5093 - val_accuracy: 0.8143 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.6030 - accuracy: 0.7820 - val_loss: 0.5046 - val_accuracy: 0.8105 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.5972 - accuracy: 0.7844 - val_loss: 0.4539 - val_accuracy: 0.8410 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.5984 - accuracy: 0.7834 - val_loss: 0.4793 - val_accuracy: 0.8321 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.5950 - accuracy: 0.7832 - val_loss: 0.4819 - val_accuracy: 0.8226 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.5963 - accuracy: 0.7839 - val_loss: 0.4667 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.5914 - accuracy: 0.7887 - val_loss: 0.4894 - val_accuracy: 0.8299 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.5883 - accuracy: 0.7869"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load and preprocess Fashion-MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape images to (28, 28, 1) for compatibility with convolutional layers\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation flow\n",
    "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 50:\n",
    "        return 0.001\n",
    "    elif epoch < 100:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=200, validation_data=(test_images, test_labels), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432cce7-3ad0-4b2e-aed7-9b36efcac5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
